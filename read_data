import os

def find_file_with_largest_prefix(directory):
    # Step 1: Get a list of files in the target directory
    files = os.listdir(directory)

    if "gfs_dataframe.parquet" in files:
        return "gfs_dataframe.parquet"

    # Step 2 and 3: Extract prefixes and determine their lengths
    prefixes_and_lengths = [(file, int(file[file.rfind('_')+1:file.find('.')])) for file in files]

    # Step 4: Identify the file with the longest prefix
    if prefixes_and_lengths:
        max_prefix_file = max(prefixes_and_lengths, key=lambda x: x[1])[0]
        return os.path.join(directory, max_prefix_file)
    else:
        return None

# Example usage:
directory_path = r"./data"
result = find_file_with_largest_prefix(directory_path)

if result:
    print(f"The file with the largest prefix is: {result}")
else:
    print("No files found in the directory.")

import pandas as pd

# Read Parquet file into a DataFrame
df = pd.read_parquet(result)

# Display the DataFrame
print(df)

import datetime

# 2015, 1, 15 start date
current_date = datetime.datetime(2015, 1, 15)
end_date = datetime.datetime(2015, 2, 15)

# coord_index = 0

# print((df['coord_index'] == 0).sum())
coord_index = ((df['coord_index']).max() + 1) * 6
current_date = current_date + datetime.timedelta(hours=coord_index)

path = current_date.strftime(r"%Y/%Y%m%d/gfs.0p25.%Y%m%d%H.f003.grib2")

print(path)